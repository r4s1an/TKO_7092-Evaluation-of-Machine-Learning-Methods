{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TKO_7092 Evaluation of Machine Learning Methods 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Student name: Ruslan Hasanov\n",
    "\n",
    "Student number: 2310614\n",
    "\n",
    "Student email: ruhasa@utu.fi\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4\n",
    "\n",
    "Complete the tasks given to you in the letter below. In your submission, explain clearly, precisely, and comprehensively why the cross-validation described in the letter failed, how cross-validation should be performed in the given scenario and why  your cross-validation will give a reliable estimate of the generalisation performance. Then implement the correct cross-validation for the scenario and report its results.\n",
    "\n",
    "Remember to follow all the general exercise guidelines that are stated in Moodle. Full points (2p) will be given for a submission that demonstrates a deep understanding of cross-validation on pair-input data and implements the requested cross-validation correctly (incl. reporting the results). Partial points (1p) will be given if there are small error(s) but the overall approach is correct. No points will be given if there are significant error(s).\n",
    "\n",
    "The deadline of this exercise is **Wednesday 21 February 2024 at 11:59 PM**. Please contact Juho Heimonen (juaheim@utu.fi) if you have any questions about this exercise.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dear Data Scientist,\n",
    "\n",
    "I have a long-term research project regarding a specific set of proteins. Currently I am attempting to discover small organic compounds that can bind strongly to these proteins and thus act as drugs. I have a list of over 100.000 potential drug molecules, but their affinities still need to be verified in the lab. Obviously I do not have the resources to measure all the possible drug-target pairs, so I need to prioritise. I have decided to do this with the use of machine learning, but I have encountered a problem.\n",
    "\n",
    "Here is what I have done so far: First I trained a K-nearest neighbours regressor with the parameter value K=10 using all the 400 measurements I had made in the lab, which comprise of all the 77 target proteins of interest but only 59 different drug molecules. Then I performed a leave-one-out cross-validation with this same data to estimate the generalisation performance of the model. I used C-index and got a stellar score above 90%. Finally I used the model to predict the affinities of the remaining drug molecules. The problem is: when I selected the highest predicted affinities and tried to verify them in the lab, I found that many of them are much lower in reality. My model clearly does not work despite the high cross-validation score.\n",
    "\n",
    "Please explain why my estimation failed and how leave-one-out cross-validation should be performed to get a reliable estimate. Also, implement the correct leave-one-out cross-validation and report its results. I need to know whether I am wasting my lab resources by using my model.\n",
    "\n",
    "The data I used to create my model is available in the files `input.data`, `output.data` and `pairs.data` for you to use. The first file contains the features of the pairs, whereas the second contains their affinities. The third file contains the identifiers of the drug and target molecules of which the pairs are composed. The files are paired, i.e. the i<sup>*th*</sup> row in each file is about the same pair.\n",
    "\n",
    "Looking forward to hearing from you soon.\n",
    "\n",
    "Yours sincerely, \\\n",
    "Bio Scientist\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer the questions about cross-validation on pair-input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why did the estimation described in the letter fail?\n",
    "# How should leave-one-out cross-validation be performed in the given scenario and why?\n",
    "# Remember to provide comprehensive and precise arguments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the leave-one-out cross validation, there is one test observation and the rest is used as training in each fold. There is also an assumption that the test set is independent of the training set, which is not the case for your situation, since you are using pair-input data. The out-of-sample observations may share similar pair members in the sample. These dependencies within pair-input data can affect the estimation of out-of-sample prediction performance. Based on the number of pair members, the out-of-sample observations are categorized into four groups. These four types of out-of-sample observations differ by the nature and extent of dependencies. For example, the out-of-sample prediction of a hypothesis is expected to be the best on type A and the worst on type D observations, as type A observations share more pair members with sample observations. To achieve a succesful performance evaluation, performance evaluation method should be adapted to the nature of pair-input data. It is necessary to estimate the out-of-sample prediction performance for each type seperately.\n",
    "\n",
    "In order to sucessfully implement the cross-validation, some changes should be made for training sets. Each type of out-of-sample observations has different rules. For the type A out-of-sample observation, there is no restriction on training dataset. For the type B, the first pair members of the test observations are not allowed to appear in the training set. For the type C, the second pair members of the test observations are not allowed to appear in the training set. For the type D, none of the pair members of the test observations are allowed to be in the training set.\n",
    "\n",
    "Judging your dataset, it can be said that your situation only involves type A and type B out-of-sample observations, as you used all the target proteins. In your case the first pair members are the drug molecules and the second pair members are target proteins. The type B out-of-sample observations include all the pairings for any other drug molecules than the used 59 drug molecules, as your measurement includes all the 77 target proteins. By following the above mentioned rules, we can implement a succesful cros-validation. \n",
    "\n",
    "Also never forget about standardization of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries you need.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import LeaveOneOut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the utility functions you need in your analysis\n",
    "\n",
    "def cindex(y, yp):\n",
    "    n = 0\n",
    "    h_num = 0\n",
    "    for i in range(0, len(y)):\n",
    "        t = y[i]\n",
    "        p = yp[i]\n",
    "        for j in range(i+1, len(y)):\n",
    "            nt = y[j]\n",
    "            np = yp[j]\n",
    "            if (t != nt):\n",
    "                n = n + 1\n",
    "                if (p < np and t < nt) or (p > np and t > nt):\n",
    "                    h_num += 1\n",
    "                elif (p == np):\n",
    "                    h_num += 0.5\n",
    "    return h_num/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dimensions of the input data are: (400, 67)\n",
      "The dimensions of the output data are: (400, 1)\n",
      "The dimensions of the pairs data are: (400, 2)\n"
     ]
    }
   ],
   "source": [
    "# Read the data files (input.data, output.data, pairs.data).\n",
    "# Read the .data file without a header row\n",
    "\n",
    "inputdata = pd.read_csv('C:\\\\Users\\\\Comp-servis\\\\Desktop\\\\Evaluation of Machine Learning Methods\\\\Exercise 4\\\\input.data',delimiter=' ', header=None)\n",
    "print('The dimensions of the input data are:', inputdata.shape)\n",
    "\n",
    "output = pd.read_csv('C:\\\\Users\\\\Comp-servis\\\\Desktop\\\\Evaluation of Machine Learning Methods\\\\Exercise 4\\\\output.data', header=None)\n",
    "print('The dimensions of the output data are:', output.shape)\n",
    "\n",
    "pairs = pd.read_csv('C:\\\\Users\\\\Comp-servis\\\\Desktop\\\\Evaluation of Machine Learning Methods\\\\Exercise 4\\\\pairs.data', delimiter=' ', header=None)\n",
    "print('The dimensions of the pairs data are:', pairs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implement and run cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The C-index value for the A-type out-of-sample observations: 0.8293691571217324\n",
      "The C-index value for the B-type out-of-sample observations: 0.5117952065887434\n"
     ]
    }
   ],
   "source": [
    "# Cross-validation for A-type out-of-sample observations\n",
    "\n",
    "# Lists to store predicted and true values\n",
    "predicted_values = []\n",
    "true_values = []\n",
    "\n",
    "# Leave-one-out cross-validator\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# An instance of StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Performing the leave-one-out cross-validation for the A-type out-of-sample observations\n",
    "for train_index, test_index in loo.split(inputdata):\n",
    "    \n",
    "    # Splitting data into training and test sets\n",
    "    X_train, X_test = inputdata.iloc[train_index], inputdata.iloc[test_index]\n",
    "    y_train, y_test = output.iloc[train_index], output.iloc[test_index]\n",
    "    \n",
    "    # Standardizing the features\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # k-nearest neighbors regressor is trained\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=10)\n",
    "    knn_regressor.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Making predictions\n",
    "    y_pred = knn_regressor.predict(X_test_scaled)\n",
    "    \n",
    "    # Storing predicted and true values for calculation of C-index value\n",
    "    predicted_values.append(y_pred[0])  # Appending the predicted value\n",
    "    true_values.append(y_test.values[0])   # Appending the true value\n",
    "\n",
    "# Calculating and printing the c-index result\n",
    "c_index = cindex(predicted_values, true_values)\n",
    "print(\"The C-index value for the A-type out-of-sample observations:\", c_index)\n",
    "\n",
    "# Cross-validation for B-type out-of-sample observations\n",
    "\n",
    "# Lists to store predicted and true values\n",
    "predicted_values = []\n",
    "true_values = []\n",
    "\n",
    "\n",
    "# Performing the leave-one-out cross-validation for the B-type out-of-sample observations\n",
    "for train_index, test_index in loo.split(inputdata):\n",
    "    \n",
    "    # Splitting data into training and test sets\n",
    "    X_train, X_test = inputdata.iloc[train_index], inputdata.iloc[test_index]\n",
    "    y_train, y_test = output.iloc[train_index], output.iloc[test_index]\n",
    "    \n",
    "    # The first member of the pair from the test data is extracted\n",
    "    first_pair_member_test = pairs.iloc[test_index[0], 0]\n",
    "    \n",
    "    # A boolean mask to filter out rows in the training data where\n",
    "    # the first member of the pair is not equal to the first member of the pair in the test data\n",
    "    mask = pairs.iloc[train_index, 0] != first_pair_member_test\n",
    "    \n",
    "    # The mask is applied to filter rows in the features (X_train) and labels (y_train) datasets\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    \n",
    "    # Standardizing the features\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # k-nearest neighbors regressor is trained\n",
    "    knn_regressor = KNeighborsRegressor(n_neighbors=10)\n",
    "    knn_regressor.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Making predictions\n",
    "    y_pred = knn_regressor.predict(X_test_scaled)\n",
    "    \n",
    "    # Storing predicted and true values for calculation of C-index value\n",
    "    predicted_values.append(y_pred[0])  # Appending the predicted value\n",
    "    true_values.append(y_test.values[0])   # Appending the true value\n",
    "\n",
    "# Calculating and printing the c-index result\n",
    "c_index = cindex(predicted_values, true_values)\n",
    "print(\"The C-index value for the B-type out-of-sample observations:\", c_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to our results, it can be said that the machine learning model exhibits different performance values for the different types of out-of-sample observations. The c-index for the A type out-of-sample observations is 0.83 which can be considered as satisfactory, however the performance metric for the B-type out-of-sample observations is 0.51, which can be regarded as random. I would not recommend to use this machine learning model to make predictions on the affinities of the drug molecules other than the used 59 drug molecules, which categorizes into the B type out-of-sample observations. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
